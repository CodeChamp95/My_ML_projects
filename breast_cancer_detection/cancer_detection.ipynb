{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries and dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder,StandardScaler\n",
    "from sklearn.model_selection import cross_val_score,train_test_split\n",
    "from sklearn.linear_model import LogisticRegression,SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report,accuracy_score,confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breast_cancer_df=pd.read_csv(\"cancer_detection.csv\")\n",
    "breast_cancer_df=breast_cancer_df.drop(labels={\n",
    "    \"Unnamed: 32\",\n",
    "    \"id\"},axis=1)\n",
    "print(breast_cancer_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing EDA on the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting the categorical columns to numeric columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le=LabelEncoder()\n",
    "breast_cancer_df[\"diagnosis\"]=le.fit_transform(breast_cancer_df[\"diagnosis\"])\n",
    "print(breast_cancer_df.head())\n",
    "print(breast_cancer_df[\"diagnosis\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would first want to have a lok at how the diagnosis is distributed, i.e. what proportion of the tumors were diagnosed as malignant or benign."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x=breast_cancer_df[\"diagnosis\"].value_counts().index,y=breast_cancer_df[\"diagnosis\"].value_counts(),hue=breast_cancer_df[\"diagnosis\"].value_counts().index)\n",
    "plt.xlabel(\"Type of tumor\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify the correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(breast_cancer_df.columns)\n",
    "correlation_matrix=breast_cancer_df.corr()\n",
    "plt.figure(figsize=(20,20))\n",
    "sns.heatmap(correlation_matrix,annot=True)\n",
    "correlation_coefficient=correlation_matrix.loc[\"diagnosis\"]\n",
    "print(correlation_coefficient.dtype)\n",
    "# print(temp_correlation_coefficient[1])\n",
    "# print(correlation_coefficient[correlation_coefficient>=0.5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there are numerous features which influence the decision about whether a tumour is malignant or benign, we will use only those features which are relevant and have high correlation with the diagnosis. Thus here we try to extract the top 15 features having the highest correlation and these features would then be used to design our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_correlation_coefficient=abs(correlation_coefficient)\n",
    "temp_correlation_coefficient=new_correlation_coefficient.sort_values(ascending=False)\n",
    "top=temp_correlation_coefficient[1:16]\n",
    "bottom=temp_correlation_coefficient[16:]\n",
    "# print(top)\n",
    "print(\"\\n\")\n",
    "top_correlation_coefficient=correlation_coefficient[top.index]\n",
    "print(top_correlation_coefficient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_breast_cancer_df=breast_cancer_df.drop(labels=bottom.index,axis=1)\n",
    "print(new_breast_cancer_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would now try to visualize the correlations of the features by using a bar chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x=top_correlation_coefficient.index,y=top_correlation_coefficient)\n",
    "plt.xticks(rotation=75)\n",
    "plt.xlabel(\"Features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also get an idea about how the values of the features themselves are distributed using a histogram for each of these features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in new_breast_cancer_df.columns:\n",
    "    plt.figure()\n",
    "    sns.histplot(new_breast_cancer_df[col],kde=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be clearly observed from the above histograms that the features are unequally distributed i.e. their ranges are not the same. This leads to issues in the modelling process where incorrect weights can be attached to the features. Thus we would like to scale the inputs to have the same range of values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler=StandardScaler()\n",
    "diagnosis_df=new_breast_cancer_df[\"diagnosis\"]\n",
    "scaled_breast_cancer_array=scaler.fit_transform(new_breast_cancer_df[top.index])\n",
    "print(scaled_breast_cancer_array.shape)\n",
    "scaled_breast_cancer_inputs=pd.DataFrame(scaled_breast_cancer_array,columns=top.index)\n",
    "scaled_breast_cancer_df=scaled_breast_cancer_inputs.join(diagnosis_df)\n",
    "print(scaled_breast_cancer_df.head(),\"\\n\",scaled_breast_cancer_df[\"diagnosis\"].value_counts())\n",
    "for col in scaled_breast_cancer_df.columns:\n",
    "    print(scaled_breast_cancer_df[col].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the dataset into training and testing sets. The model is trained using only the training set while the test set is then used to check whether the model performs similarly when confronted with previously unknown data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "breast_cancer_train,breast_cancer_test=train_test_split(scaled_breast_cancer_df,test_size=0.2,random_state=42,shuffle=True,stratify=scaled_breast_cancer_df[\"diagnosis\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have diagnosis as a categorical column in this dataset which also happens to be our target variable. Thus we would like this variable to be distributed in equal proportion in both the testing and training sets. As a result, we have stratified the diagnosis column. This is important as we do not want higher values of 0 in one set and higher values of 1 in the other. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breast_cancer_train.diagnosis.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breast_cancer_test.diagnosis.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we would try to analyze the results obtained by using various classification models and noting down the evaluation metrics. Various models such as Logistic Regression, Decision Tree, Random Forest, Naive Bayes, KNN,etc. will be used for the comparison. Metrics such as confusion matrix, accuracy score and classification report would be used. We would also have a look at the weights assigned to each of the features by these models and compare them with the coefficients obtained during the data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_evaluation_train(model):\n",
    "    train_inputs=breast_cancer_train[top.index]\n",
    "    train_targets=breast_cancer_train[\"diagnosis\"]\n",
    "    model.fit(train_inputs,train_targets)\n",
    "    train_predictions=model.predict(train_inputs)\n",
    "    print(classification_report(train_targets,train_predictions))\n",
    "    print(confusion_matrix(train_targets,train_predictions))\n",
    "    train_accuracy=accuracy_score(train_targets,train_predictions)\n",
    "    print(train_accuracy)\n",
    "\n",
    "    test_inputs=breast_cancer_test[top.index]\n",
    "    test_targets=breast_cancer_test[\"diagnosis\"]\n",
    "    test_predictions=model.predict(test_inputs)\n",
    "    print(classification_report(test_targets,test_predictions))\n",
    "    print(confusion_matrix(test_targets,test_predictions))\n",
    "    test_accuracy=accuracy_score(test_targets,test_predictions)\n",
    "    print(test_accuracy)\n",
    "\n",
    "    return train_accuracy,test_accuracy\n",
    "\n",
    "    # weights=model.coef_\n",
    "    # print(weights)\n",
    "    # sns.barplot(x=top.index,y=weights.flatten())\n",
    "    # plt.xticks(rotation=75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_train_accuracy,logistic_test_accuracy=model_evaluation_train(LogisticRegression())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_train_accuracy,dt_test_accuracy=model_evaluation_train(DecisionTreeClassifier())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_train_accuracy,rf_test_accuracy=model_evaluation_train(RandomForestClassifier())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_train_accuarcy,knn_test_accuracy=model_evaluation_train(KNeighborsClassifier())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN with custom number of neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modifiedknn_train_accuracy,modifiedknn_test_accuracy=model_evaluation_train(KNeighborsClassifier(n_neighbors=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bayes_train_accuracy,bayes_test_accuracy=model_evaluation_train(GaussianNB())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_train_accuracy,sgd_test_accuracy=model_evaluation_train(SGDClassifier())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_train_accuracy,svc_test_accuracy=model_evaluation_train(SVC())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_train_accuracy,xg_test_accuracy=model_evaluation_train(XGBClassifier())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_train_accuracy,gb_test_accuracy=model_evaluation_train(GradientBoostingClassifier())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the results and comparing the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_array=np.array([[\"LogisticRegression\",logistic_train_accuracy,logistic_test_accuracy],[\"DecisionTreeClassifier\",dt_train_accuracy,dt_test_accuracy],[\"RandomForestClassifier\",rf_train_accuracy,rf_test_accuracy],[\"KNeighborsClassifier\",knn_train_accuarcy,knn_test_accuracy],[\"KNeighborsClassifierWith3Neighbours\",modifiedknn_train_accuracy,modifiedknn_test_accuracy],[\"Naive Bayes\",bayes_train_accuracy,bayes_test_accuracy],[\"SGDClassifier\",sgd_train_accuracy,sgd_test_accuracy],[\"SVC\",svc_train_accuracy,svc_test_accuracy],[\"XGBClassifier\",xg_train_accuracy,xg_test_accuracy],[\"GradientBoostingClassifier\",gb_train_accuracy,gb_test_accuracy]])\n",
    "# print(results_array.shape)\n",
    "\n",
    "results_df=pd.DataFrame(data=results_array,columns=[\"models\",\"train_scores\",\"test_scores\"])\n",
    "# print(results_df.head())\n",
    "results_df[\"train_scores\"]=pd.to_numeric(results_df[\"train_scores\"])\n",
    "results_df[\"test_scores\"]=pd.to_numeric(results_df[\"test_scores\"])\n",
    "# print(results_df.head(),\"\\n\",results_df[\"train_scores\"].dtype,results_df[\"test_scores\"].dtype)\n",
    "\n",
    "results_df.plot(kind=\"bar\",xlabel=\"models\",ylabel=\"scores\",x=\"models\",color=[\"mediumpurple\",\"rebeccapurple\"],title=\"Model Comparison\")\n",
    "plt.xticks(rotation=85)\n",
    "plt.ylim([0.9,1.0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the model comparison bar chart we can observe that: \n",
    "1. Some models like DecisionTree, RandomForest, XGBoost and Gradient Boosting have overfitted the data as they give 100% accuracy. However this shortfall is clearly visible whne compared with the accuracy obtained on the test data, which are lower compared to 100%. \n",
    "2. The SVC model shows similar accuracy for both training and testing data and also has a higher accuracy of almost 96%. This indicates that the SVC model could be a suitable choice for the breast cancer detection.\n",
    "3. The k-nearest neighbours model was used with two different parameters: the default model where the number of neighbours is 5 and a modified version where we took the number of neighbours as 3. We can observe that the modified model gives a higher accuracy score than the default, although the deviation from the accuracy on the test data is higher for the modified model. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
